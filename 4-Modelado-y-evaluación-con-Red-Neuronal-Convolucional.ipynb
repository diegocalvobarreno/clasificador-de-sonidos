{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clasificación de sonido ambiente \n",
    "---\n",
    "# Modelado y evaluación de Red Neuronal Convolucional\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con el fin de mejorar la precisión de la red neuronal multicapa, con una precisión del 87% se plantea la resolución mediante una red neuronal convolucional"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para ello se precargan datos del notebook 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieve the preprocessed data from previous notebook\n",
    "\n",
    "%store -r x_train \n",
    "%store -r x_test \n",
    "%store -r y_train \n",
    "%store -r y_test \n",
    "%store -r yy \n",
    "%store -r le\n",
    "%store -r fulldatasetpath\n",
    "%store -r metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracción de caracteristicas refinada\n",
    "En la etapa de extracción de características anterior, los vectores MFCC variarían en tamaño para los diferentes archivos de audio (dependiendo de la duración de las muestras).\n",
    "\n",
    "Las CNN requieren un tamaño fijo para todas las entradas, por ello vremos cual es el máximo y rellenaremos a cero los vectores de salida inferiores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "max_pad_len = 174\n",
    "\n",
    "def extract_features(file_name):\n",
    "   \n",
    "    try:\n",
    "        audio, sample_rate = librosa.load(file_name, res_type='kaiser_fast') \n",
    "        mfccs = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=40)\n",
    "        pad_width = max_pad_len - mfccs.shape[1]\n",
    "        mfccs = np.pad(mfccs, pad_width=((0, 0), (0, pad_width)), mode='constant')\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(\"Error encountered while parsing file: \", file_name)\n",
    "        return None \n",
    "     \n",
    "    return mfccs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished feature extraction from  40  files\n"
     ]
    }
   ],
   "source": [
    "# Load various imports \n",
    "import pandas as pd\n",
    "import os\n",
    "import librosa\n",
    "\n",
    "features = []\n",
    "\n",
    "# Iterate through each sound file and extract the features \n",
    "for index, row in metadata.iterrows():\n",
    "    \n",
    "    file_name = os.path.join(os.path.abspath(fulldatasetpath),'fold'+str(row[\"fold\"])+'/',str(row[\"slice_file_name\"]))\n",
    "    \n",
    "    class_label = row[\"classID\"]\n",
    "    data = extract_features(file_name)\n",
    "    \n",
    "    features.append([data, class_label])\n",
    "\n",
    "# Convert into a Panda dataframe \n",
    "featuresdf = pd.DataFrame(features, columns=['feature','class_label'])\n",
    "\n",
    "print('Finished feature extraction from ', len(featuresdf), ' files') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convertir los datos y etiquetas\n",
    "Para transformarlos datos categóricos a numéricos usaremos \"LabelEncoder\" y así conseguiremos que el modelo sea capaz de entenderlos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "# Convert features and corresponding classification labels into numpy arrays\n",
    "X = np.array(featuresdf.feature.tolist())\n",
    "y = np.array(featuresdf.class_label.tolist())\n",
    "\n",
    "# Encode the classification labels\n",
    "le = LabelEncoder()\n",
    "yy = to_categorical(le.fit_transform(y)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dividir los datos en entrenamiento y test\n",
    "Dividimos el conjunto de datos en dos bloques (80% y 20%) y de ellos sacamos valores de X y de Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the dataset \n",
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, yy, test_size=0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construir el modelo\n",
    "\n",
    "Utilizaremos un modelo secuencial, comenzando con una arquitectura de modelo simple, que consta de cuatro capas de convolución Conv2D con sus capas de poolling, siendo nuestra capa de salida final una capa densa.\n",
    "\n",
    "Las capas de convolución están diseñadas para la detección de características. Funciona deslizando una ventana de filtro `filter` sobre la entrada y realizando una multiplicación de matriz y almacenando el resultado en un mapa de características. Esta operación se conoce como convolución.\n",
    "\n",
    "El parámetro de filtro especifica el número de nodos en cada capa. Cada capa aumentará de tamaño de 16, 32, 64 a 128, mientras que el parámetro `kernel_size` especifica el tamaño de la ventana del kernel, que en este caso es 2, lo que da como resultado una matriz de filtro 2x2.\n",
    "\n",
    "La primera capa recibirá la forma de entrada de (40, 174, 1) donde 40 es el número de MFCC 174 es el número de cuadros que tienen en cuenta el relleno y el 1 significa que el audio es mono.\n",
    "\n",
    "La función de activación que utilizaremos para nuestras capas convolucionales es ReLU.\n",
    "\n",
    "También destacar que aplicaremos un `Dropout` del 20%. Esto excluirá al azar los nodos de cada ciclo de actualización, lo que a su vez da como resultado una red que es capaz de respondr mejor a la generalización y es menos probable se produzca sobreajuste los datos de entrenamiento.\n",
    "\n",
    "Cada capa convolucional tiene una capa de agrupación asociada de tipo `MaxPooling2D` con la capa convolucional final que tiene un tipo `GlobalAveragePooling2D`. La capa de agrupación reduce la dimensionalidad del modelo (al reducir los parámetros y los requisitos de cálculo subsiguientes), lo que sirve para acortar el tiempo de entrenamiento y reducir el sobreajuste. El tipo de agrupación máxima toma el tamaño máximo para cada ventana y el tipo de agrupación promedio global toma el promedio que es adecuado para alimentar nuestra capa de salida densa.\n",
    "\n",
    "Finalmente la capa de salida tendrá 10 nodos, que coinciden con el número de clasificaciones posibles. La activación es para nuestra capa de salida es softmax. Softmax hace que la salida sume 1, por lo que la salida puede interpretarse como probabilidades. El modelo hará su predicción según la opción que tenga la mayor probabilidad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Convolution2D, Conv2D, MaxPooling2D, GlobalAveragePooling2D\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import np_utils\n",
    "from sklearn import metrics \n",
    "\n",
    "num_rows = 40\n",
    "num_columns = 174\n",
    "num_channels = 1\n",
    "\n",
    "x_train = x_train.reshape(x_train.shape[0], num_rows, num_columns, num_channels)\n",
    "x_test = x_test.reshape(x_test.shape[0], num_rows, num_columns, num_channels)\n",
    "\n",
    "num_labels = yy.shape[1]\n",
    "filter_size = 2\n",
    "\n",
    "# Construct model \n",
    "model = Sequential()\n",
    "model.add(Conv2D(filters=16, kernel_size=2, input_shape=(num_rows, num_columns, num_channels), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv2D(filters=32, kernel_size=2, activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv2D(filters=64, kernel_size=2, activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv2D(filters=128, kernel_size=2, activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(GlobalAveragePooling2D())\n",
    "\n",
    "model.add(Dense(num_labels, activation='softmax')) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compiling the model \n",
    "\n",
    "Para compilar nuestro modelo, utilizaremos los siguientes tres parámetros:\n",
    "\n",
    "* Función de pérdida: utilizaremos `categorical_crossentropy`. Esta es la opción más común para la clasificación. Una puntuación más baja indica que el modelo está funcionando mejor.\n",
    "\n",
    "* Métricas: utilizaremos la métrica de `accuracy` que nos permitirá ver el puntaje de precisión en los datos de validación cuando entrenemos el modelo.\n",
    "\n",
    "* Optimizador: aquí usaremos `adam`, que generalmente es un buen optimizador para muchos casos de uso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_9 (Conv2D)            (None, 39, 173, 16)       80        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 19, 86, 16)        0         \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 19, 86, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 18, 85, 32)        2080      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 9, 42, 32)         0         \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 9, 42, 32)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 8, 41, 64)         8256      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling (None, 4, 20, 64)         0         \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 4, 20, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 3, 19, 128)        32896     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling (None, 1, 9, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 1, 9, 128)         0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_3 ( (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 44,602\n",
      "Trainable params: 44,602\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "8/8 [==============================] - 1s 85ms/step\n",
      "Pre-training accuracy: 12.5000%\n"
     ]
    }
   ],
   "source": [
    "# Display model architecture summary \n",
    "model.summary()\n",
    "\n",
    "# Calculate pre-training accuracy \n",
    "score = model.evaluate(x_test, y_test, verbose=1)\n",
    "accuracy = 100*score[1]\n",
    "\n",
    "print(\"Pre-training accuracy: %.4f%%\" % accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenar el modelo\n",
    "\n",
    "Se empieza probando con un número de epocas baja y se prueba hasta ver donde alcanza un valor asintotico donde por más que subamos las epocas no conseguimos que el modelo mejore significativamente.\n",
    "\n",
    "Por otro el tamaño del bloje debe ser suficientemente bajo, ya que tener un tamaño de lote grande puede reducir la capacidad de generalización del modelo. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 32 samples, validate on 8 samples\n",
      "Epoch 1/72\n",
      "32/32 [==============================] - 5s 157ms/step - loss: 11.3753 - accuracy: 0.1250 - val_loss: 5.8565 - val_accuracy: 0.1250\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 5.85652, saving model to saved_models/weights.best.basic_cnn.hdf5\n",
      "Epoch 2/72\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 8.7740 - accuracy: 0.0625 - val_loss: 4.6509 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00002: val_loss improved from 5.85652 to 4.65091, saving model to saved_models/weights.best.basic_cnn.hdf5\n",
      "Epoch 3/72\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 5.5035 - accuracy: 0.0938 - val_loss: 4.1477 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00003: val_loss improved from 4.65091 to 4.14774, saving model to saved_models/weights.best.basic_cnn.hdf5\n",
      "Epoch 4/72\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 6.5338 - accuracy: 0.1562 - val_loss: 3.6241 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00004: val_loss improved from 4.14774 to 3.62407, saving model to saved_models/weights.best.basic_cnn.hdf5\n",
      "Epoch 5/72\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 5.7677 - accuracy: 0.0625 - val_loss: 3.3804 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00005: val_loss improved from 3.62407 to 3.38040, saving model to saved_models/weights.best.basic_cnn.hdf5\n",
      "Epoch 6/72\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 4.8823 - accuracy: 0.1250 - val_loss: 3.1747 - val_accuracy: 0.1250\n",
      "\n",
      "Epoch 00006: val_loss improved from 3.38040 to 3.17472, saving model to saved_models/weights.best.basic_cnn.hdf5\n",
      "Epoch 7/72\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 4.4038 - accuracy: 0.1562 - val_loss: 3.0882 - val_accuracy: 0.1250\n",
      "\n",
      "Epoch 00007: val_loss improved from 3.17472 to 3.08823, saving model to saved_models/weights.best.basic_cnn.hdf5\n",
      "Epoch 8/72\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 3.4868 - accuracy: 0.2500 - val_loss: 3.1370 - val_accuracy: 0.1250\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 3.08823\n",
      "Epoch 9/72\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 2.9488 - accuracy: 0.2812 - val_loss: 3.0381 - val_accuracy: 0.1250\n",
      "\n",
      "Epoch 00009: val_loss improved from 3.08823 to 3.03808, saving model to saved_models/weights.best.basic_cnn.hdf5\n",
      "Epoch 10/72\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 2.9891 - accuracy: 0.3125 - val_loss: 2.8715 - val_accuracy: 0.1250\n",
      "\n",
      "Epoch 00010: val_loss improved from 3.03808 to 2.87154, saving model to saved_models/weights.best.basic_cnn.hdf5\n",
      "Epoch 11/72\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 2.8550 - accuracy: 0.2500 - val_loss: 2.7089 - val_accuracy: 0.1250\n",
      "\n",
      "Epoch 00011: val_loss improved from 2.87154 to 2.70887, saving model to saved_models/weights.best.basic_cnn.hdf5\n",
      "Epoch 12/72\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 2.7831 - accuracy: 0.2188 - val_loss: 2.5310 - val_accuracy: 0.2500\n",
      "\n",
      "Epoch 00012: val_loss improved from 2.70887 to 2.53099, saving model to saved_models/weights.best.basic_cnn.hdf5\n",
      "Epoch 13/72\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 2.1867 - accuracy: 0.4062 - val_loss: 2.3241 - val_accuracy: 0.2500\n",
      "\n",
      "Epoch 00013: val_loss improved from 2.53099 to 2.32410, saving model to saved_models/weights.best.basic_cnn.hdf5\n",
      "Epoch 14/72\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 1.9065 - accuracy: 0.4688 - val_loss: 2.0981 - val_accuracy: 0.2500\n",
      "\n",
      "Epoch 00014: val_loss improved from 2.32410 to 2.09808, saving model to saved_models/weights.best.basic_cnn.hdf5\n",
      "Epoch 15/72\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 1.7962 - accuracy: 0.3750 - val_loss: 1.8773 - val_accuracy: 0.3750\n",
      "\n",
      "Epoch 00015: val_loss improved from 2.09808 to 1.87733, saving model to saved_models/weights.best.basic_cnn.hdf5\n",
      "Epoch 16/72\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 1.7281 - accuracy: 0.5000 - val_loss: 1.7373 - val_accuracy: 0.3750\n",
      "\n",
      "Epoch 00016: val_loss improved from 1.87733 to 1.73732, saving model to saved_models/weights.best.basic_cnn.hdf5\n",
      "Epoch 17/72\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.4076 - accuracy: 0.5625 - val_loss: 1.6423 - val_accuracy: 0.5000\n",
      "\n",
      "Epoch 00017: val_loss improved from 1.73732 to 1.64227, saving model to saved_models/weights.best.basic_cnn.hdf5\n",
      "Epoch 18/72\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 1.7046 - accuracy: 0.5000 - val_loss: 1.6007 - val_accuracy: 0.5000\n",
      "\n",
      "Epoch 00018: val_loss improved from 1.64227 to 1.60073, saving model to saved_models/weights.best.basic_cnn.hdf5\n",
      "Epoch 19/72\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 1.4155 - accuracy: 0.5312 - val_loss: 1.5980 - val_accuracy: 0.5000\n",
      "\n",
      "Epoch 00019: val_loss improved from 1.60073 to 1.59802, saving model to saved_models/weights.best.basic_cnn.hdf5\n",
      "Epoch 20/72\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 1.1796 - accuracy: 0.6250 - val_loss: 1.5959 - val_accuracy: 0.5000\n",
      "\n",
      "Epoch 00020: val_loss improved from 1.59802 to 1.59587, saving model to saved_models/weights.best.basic_cnn.hdf5\n",
      "Epoch 21/72\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 1.1296 - accuracy: 0.5312 - val_loss: 1.6042 - val_accuracy: 0.7500\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 1.59587\n",
      "Epoch 22/72\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 1.0937 - accuracy: 0.6250 - val_loss: 1.6105 - val_accuracy: 0.7500\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 1.59587\n",
      "Epoch 23/72\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.9486 - accuracy: 0.6875 - val_loss: 1.6096 - val_accuracy: 0.7500\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 1.59587\n",
      "Epoch 24/72\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.8492 - accuracy: 0.6562 - val_loss: 1.5927 - val_accuracy: 0.7500\n",
      "\n",
      "Epoch 00024: val_loss improved from 1.59587 to 1.59273, saving model to saved_models/weights.best.basic_cnn.hdf5\n",
      "Epoch 25/72\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 1.0266 - accuracy: 0.6875 - val_loss: 1.5645 - val_accuracy: 0.6250\n",
      "\n",
      "Epoch 00025: val_loss improved from 1.59273 to 1.56451, saving model to saved_models/weights.best.basic_cnn.hdf5\n",
      "Epoch 26/72\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.7727 - accuracy: 0.8125 - val_loss: 1.5315 - val_accuracy: 0.5000\n",
      "\n",
      "Epoch 00026: val_loss improved from 1.56451 to 1.53150, saving model to saved_models/weights.best.basic_cnn.hdf5\n",
      "Epoch 27/72\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.6731 - accuracy: 0.7812 - val_loss: 1.4986 - val_accuracy: 0.5000\n",
      "\n",
      "Epoch 00027: val_loss improved from 1.53150 to 1.49860, saving model to saved_models/weights.best.basic_cnn.hdf5\n",
      "Epoch 28/72\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.5803 - accuracy: 0.8750 - val_loss: 1.4619 - val_accuracy: 0.5000\n",
      "\n",
      "Epoch 00028: val_loss improved from 1.49860 to 1.46191, saving model to saved_models/weights.best.basic_cnn.hdf5\n",
      "Epoch 29/72\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.7396 - accuracy: 0.7812 - val_loss: 1.4184 - val_accuracy: 0.5000\n",
      "\n",
      "Epoch 00029: val_loss improved from 1.46191 to 1.41836, saving model to saved_models/weights.best.basic_cnn.hdf5\n",
      "Epoch 30/72\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.7449 - accuracy: 0.7188 - val_loss: 1.3708 - val_accuracy: 0.5000\n",
      "\n",
      "Epoch 00030: val_loss improved from 1.41836 to 1.37084, saving model to saved_models/weights.best.basic_cnn.hdf5\n",
      "Epoch 31/72\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.6317 - accuracy: 0.7500 - val_loss: 1.3225 - val_accuracy: 0.5000\n",
      "\n",
      "Epoch 00031: val_loss improved from 1.37084 to 1.32254, saving model to saved_models/weights.best.basic_cnn.hdf5\n",
      "Epoch 32/72\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.6613 - accuracy: 0.7500 - val_loss: 1.2794 - val_accuracy: 0.5000\n",
      "\n",
      "Epoch 00032: val_loss improved from 1.32254 to 1.27935, saving model to saved_models/weights.best.basic_cnn.hdf5\n",
      "Epoch 33/72\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.5693 - accuracy: 0.7812 - val_loss: 1.2398 - val_accuracy: 0.6250\n",
      "\n",
      "Epoch 00033: val_loss improved from 1.27935 to 1.23984, saving model to saved_models/weights.best.basic_cnn.hdf5\n",
      "Epoch 34/72\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 7ms/step - loss: 0.5645 - accuracy: 0.8438 - val_loss: 1.1948 - val_accuracy: 0.7500\n",
      "\n",
      "Epoch 00034: val_loss improved from 1.23984 to 1.19479, saving model to saved_models/weights.best.basic_cnn.hdf5\n",
      "Epoch 35/72\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.6313 - accuracy: 0.8438 - val_loss: 1.1345 - val_accuracy: 0.7500\n",
      "\n",
      "Epoch 00035: val_loss improved from 1.19479 to 1.13453, saving model to saved_models/weights.best.basic_cnn.hdf5\n",
      "Epoch 36/72\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.5186 - accuracy: 0.8438 - val_loss: 1.0646 - val_accuracy: 0.7500\n",
      "\n",
      "Epoch 00036: val_loss improved from 1.13453 to 1.06464, saving model to saved_models/weights.best.basic_cnn.hdf5\n",
      "Epoch 37/72\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.4697 - accuracy: 0.8438 - val_loss: 0.9876 - val_accuracy: 0.7500\n",
      "\n",
      "Epoch 00037: val_loss improved from 1.06464 to 0.98758, saving model to saved_models/weights.best.basic_cnn.hdf5\n",
      "Epoch 38/72\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.4362 - accuracy: 0.9375 - val_loss: 0.9195 - val_accuracy: 0.7500\n",
      "\n",
      "Epoch 00038: val_loss improved from 0.98758 to 0.91953, saving model to saved_models/weights.best.basic_cnn.hdf5\n",
      "Epoch 39/72\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.5573 - accuracy: 0.8125 - val_loss: 0.8604 - val_accuracy: 0.7500\n",
      "\n",
      "Epoch 00039: val_loss improved from 0.91953 to 0.86043, saving model to saved_models/weights.best.basic_cnn.hdf5\n",
      "Epoch 40/72\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.3793 - accuracy: 0.9375 - val_loss: 0.8046 - val_accuracy: 0.8750\n",
      "\n",
      "Epoch 00040: val_loss improved from 0.86043 to 0.80459, saving model to saved_models/weights.best.basic_cnn.hdf5\n",
      "Epoch 41/72\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.3262 - accuracy: 0.9062 - val_loss: 0.7554 - val_accuracy: 0.8750\n",
      "\n",
      "Epoch 00041: val_loss improved from 0.80459 to 0.75538, saving model to saved_models/weights.best.basic_cnn.hdf5\n",
      "Epoch 42/72\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.3034 - accuracy: 1.0000 - val_loss: 0.7180 - val_accuracy: 0.8750\n",
      "\n",
      "Epoch 00042: val_loss improved from 0.75538 to 0.71795, saving model to saved_models/weights.best.basic_cnn.hdf5\n",
      "Epoch 43/72\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.3564 - accuracy: 0.9062 - val_loss: 0.6932 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00043: val_loss improved from 0.71795 to 0.69319, saving model to saved_models/weights.best.basic_cnn.hdf5\n",
      "Epoch 44/72\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.3767 - accuracy: 0.8438 - val_loss: 0.6753 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00044: val_loss improved from 0.69319 to 0.67529, saving model to saved_models/weights.best.basic_cnn.hdf5\n",
      "Epoch 45/72\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.3239 - accuracy: 0.9375 - val_loss: 0.6648 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00045: val_loss improved from 0.67529 to 0.66477, saving model to saved_models/weights.best.basic_cnn.hdf5\n",
      "Epoch 46/72\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.2997 - accuracy: 0.9688 - val_loss: 0.6504 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00046: val_loss improved from 0.66477 to 0.65040, saving model to saved_models/weights.best.basic_cnn.hdf5\n",
      "Epoch 47/72\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.3168 - accuracy: 0.9375 - val_loss: 0.6257 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00047: val_loss improved from 0.65040 to 0.62565, saving model to saved_models/weights.best.basic_cnn.hdf5\n",
      "Epoch 48/72\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.2497 - accuracy: 1.0000 - val_loss: 0.5956 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00048: val_loss improved from 0.62565 to 0.59557, saving model to saved_models/weights.best.basic_cnn.hdf5\n",
      "Epoch 49/72\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.2414 - accuracy: 1.0000 - val_loss: 0.5688 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00049: val_loss improved from 0.59557 to 0.56884, saving model to saved_models/weights.best.basic_cnn.hdf5\n",
      "Epoch 50/72\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.2491 - accuracy: 0.9688 - val_loss: 0.5444 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00050: val_loss improved from 0.56884 to 0.54442, saving model to saved_models/weights.best.basic_cnn.hdf5\n",
      "Epoch 51/72\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.2037 - accuracy: 1.0000 - val_loss: 0.5212 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00051: val_loss improved from 0.54442 to 0.52125, saving model to saved_models/weights.best.basic_cnn.hdf5\n",
      "Epoch 52/72\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.2210 - accuracy: 1.0000 - val_loss: 0.5021 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00052: val_loss improved from 0.52125 to 0.50207, saving model to saved_models/weights.best.basic_cnn.hdf5\n",
      "Epoch 53/72\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.1865 - accuracy: 1.0000 - val_loss: 0.4823 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00053: val_loss improved from 0.50207 to 0.48234, saving model to saved_models/weights.best.basic_cnn.hdf5\n",
      "Epoch 54/72\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.2323 - accuracy: 0.9375 - val_loss: 0.4671 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00054: val_loss improved from 0.48234 to 0.46710, saving model to saved_models/weights.best.basic_cnn.hdf5\n",
      "Epoch 55/72\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.2076 - accuracy: 1.0000 - val_loss: 0.4506 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00055: val_loss improved from 0.46710 to 0.45060, saving model to saved_models/weights.best.basic_cnn.hdf5\n",
      "Epoch 56/72\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.2099 - accuracy: 0.9688 - val_loss: 0.4373 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00056: val_loss improved from 0.45060 to 0.43733, saving model to saved_models/weights.best.basic_cnn.hdf5\n",
      "Epoch 57/72\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.1527 - accuracy: 1.0000 - val_loss: 0.4235 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00057: val_loss improved from 0.43733 to 0.42346, saving model to saved_models/weights.best.basic_cnn.hdf5\n",
      "Epoch 58/72\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.2996 - accuracy: 0.9375 - val_loss: 0.4030 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00058: val_loss improved from 0.42346 to 0.40295, saving model to saved_models/weights.best.basic_cnn.hdf5\n",
      "Epoch 59/72\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.2245 - accuracy: 1.0000 - val_loss: 0.3802 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00059: val_loss improved from 0.40295 to 0.38015, saving model to saved_models/weights.best.basic_cnn.hdf5\n",
      "Epoch 60/72\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.2121 - accuracy: 0.9375 - val_loss: 0.3555 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00060: val_loss improved from 0.38015 to 0.35551, saving model to saved_models/weights.best.basic_cnn.hdf5\n",
      "Epoch 61/72\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.2294 - accuracy: 0.9688 - val_loss: 0.3280 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00061: val_loss improved from 0.35551 to 0.32804, saving model to saved_models/weights.best.basic_cnn.hdf5\n",
      "Epoch 62/72\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.1170 - accuracy: 1.0000 - val_loss: 0.3041 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00062: val_loss improved from 0.32804 to 0.30410, saving model to saved_models/weights.best.basic_cnn.hdf5\n",
      "Epoch 63/72\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.2121 - accuracy: 0.9688 - val_loss: 0.2819 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00063: val_loss improved from 0.30410 to 0.28187, saving model to saved_models/weights.best.basic_cnn.hdf5\n",
      "Epoch 64/72\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.1336 - accuracy: 1.0000 - val_loss: 0.2618 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00064: val_loss improved from 0.28187 to 0.26178, saving model to saved_models/weights.best.basic_cnn.hdf5\n",
      "Epoch 65/72\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.1363 - accuracy: 0.9688 - val_loss: 0.2460 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00065: val_loss improved from 0.26178 to 0.24603, saving model to saved_models/weights.best.basic_cnn.hdf5\n",
      "Epoch 66/72\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.1582 - accuracy: 0.9062 - val_loss: 0.2346 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00066: val_loss improved from 0.24603 to 0.23462, saving model to saved_models/weights.best.basic_cnn.hdf5\n",
      "Epoch 67/72\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.1230 - accuracy: 0.9688 - val_loss: 0.2221 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00067: val_loss improved from 0.23462 to 0.22206, saving model to saved_models/weights.best.basic_cnn.hdf5\n",
      "Epoch 68/72\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.1105 - accuracy: 0.9688 - val_loss: 0.2130 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00068: val_loss improved from 0.22206 to 0.21299, saving model to saved_models/weights.best.basic_cnn.hdf5\n",
      "Epoch 69/72\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0867 - accuracy: 1.0000 - val_loss: 0.2056 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00069: val_loss improved from 0.21299 to 0.20560, saving model to saved_models/weights.best.basic_cnn.hdf5\n",
      "Epoch 70/72\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0911 - accuracy: 1.0000 - val_loss: 0.1990 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00070: val_loss improved from 0.20560 to 0.19900, saving model to saved_models/weights.best.basic_cnn.hdf5\n",
      "Epoch 71/72\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.1093 - accuracy: 1.0000 - val_loss: 0.1930 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00071: val_loss improved from 0.19900 to 0.19301, saving model to saved_models/weights.best.basic_cnn.hdf5\n",
      "Epoch 72/72\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1240 - accuracy: 0.9688 - val_loss: 0.1872 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00072: val_loss improved from 0.19301 to 0.18723, saving model to saved_models/weights.best.basic_cnn.hdf5\n",
      "Training completed in time:  0:00:27.127249\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint \n",
    "from datetime import datetime \n",
    "\n",
    "#num_epochs = 12\n",
    "#num_batch_size = 128\n",
    "\n",
    "num_epochs = 72\n",
    "num_batch_size = 256\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath='saved_models/weights.best.basic_cnn.hdf5', \n",
    "                               verbose=1, save_best_only=True)\n",
    "start = datetime.now()\n",
    "\n",
    "model.fit(x_train, y_train, batch_size=num_batch_size, epochs=num_epochs, validation_data=(x_test, y_test), callbacks=[checkpointer], verbose=1)\n",
    "\n",
    "\n",
    "duration = datetime.now() - start\n",
    "print(\"Training completed in time: \", duration)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluar el modelo\n",
    "Finalmente para determiar la precisión del modelo generado llamamos a la función evaluate y le pasamos los datos de test que hemos definido previamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Accuracy:  1.0\n"
     ]
    }
   ],
   "source": [
    "# Evaluating the model on the testing set\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print(\"Testing Accuracy: \", score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si analizamos el valor obtenido con todo el conjunto de test, teniendo en cuenta el conjunto de datos completo vemos podríamos ver que la precisión a mejorado entorno al 6% "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
